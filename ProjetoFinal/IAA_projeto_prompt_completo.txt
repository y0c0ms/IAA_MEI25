[PARTE 1 – ENUNCIADO EM FORMATO PROMPT]

Estou a fazer o projeto final da UC “Introduction to Machine Learning – 2025/2026”. O objetivo é aplicar a metodologia CRISP‑DM (todas as fases exceto Deployment) a um conjunto de dados de consumo de energia elétrica do Município da Maia, para:
1. Caracterizar diferentes consumidores.
2. Avaliar a capacidade preditiva para séries temporais de energia.

O dataset chama-se D4Maia e contém cerca de 6×10^6 registos com 7 atributos, com leituras de energia de vários edifícios de serviços municipais, com medições de 15 em 15 minutos. Cada linha corresponde a uma leitura num dado local e instante. As colunas são:
- id – identificador da amostra
- CPE – código do local (cliente / instalação)
- hora – instante da leitura
- DadosDeConsumo – consumo usado para faturação (kWh)
- PotAtiva – potência ativa usada para calcular o consumo (kWh)
- PotReactIndut – potência reativa indutiva (VAR)
- PotReactCapac – potência reativa capacitiva (VAR)

A potência reativa é relevante para a análise exploratória, mas pode ser ignorada na parte de modelação de séries temporais (ARIMA / LSTM).

O projeto tem de:
- Seguir explicitamente as fases do CRISP‑DM (Business Understanding, Data Understanding, Data Preparation, Modeling, Evaluation), articulando os resultados práticos com a teoria vista nos slides.
- Utilizar Python notebooks como forma principal de desenvolvimento e de relatório técnico integrado com o código.
- Entregar também datasets intermédios usados na modelação (por exemplo, ficheiros com features por CPE, ficheiros com séries por CPE).

EXPERIÊNCIAS OBRIGATÓRIAS

1) Clustering / Aprendizagem não supervisionada
- Usar algoritmos de clustering (sugeridos: K‑Means e DBSCAN) para identificar sub‑grupos de consumidores, detetar outliers e, se possível, relacionar perfis com tipos de serviços (serviços diurnos, noturnos, 24/7, etc.).
- As decisões (número de clusters, parâmetros de DBSCAN, normalização, etc.) devem ser claramente justificadas.
- Avaliar a qualidade dos clusters com métricas adequadas (por exemplo, silhouette score, métricas de separação/compactação) e interpretação dos perfis.

2) Previsão de séries temporais – Experiência 2(a)
- Modelos de previsão de uma semana à frente, por CPE, usando séries temporais diretamente.
- Dividir cada série em:
  • 70% inicial → treino
  • 30% final → teste
- Usar pelo menos:
  • Um modelo clássico de séries temporais (ARIMA)
  • Um modelo baseado em redes neuronais LSTM
- O alvo da previsão é o valor de DadosDeConsumo ou PotAtiva num dado instante futuro.
- Comparar os resultados com uma baseline ingénua: o consumo previsto numa data/hora é igual ao consumo na mesma data/hora da semana anterior.

3) Previsão baseada em features – Experiência 2(b)
- Construir conjuntos de features por CPE (agregações temporais, estatísticas de consumo, padrões diários/semanais, etc.), respeitando que todas as features usadas para prever um instante têm de ser calculadas com dados de pelo menos uma semana antes desse instante.
- Usar estes feature sets como input de modelos supervisionados como:
  • Random Forest
  • XGBoost
  • MLP
- Comparar desempenho destes modelos com a baseline e com ARIMA/LSTM.

4) Experiência de normalização de dados
- Repetir ou complementar experiências com e sem normalização das variáveis (por exemplo StandardScaler, MinMaxScaler), avaliando o impacto:
  • Na estabilidade e forma dos clusters (K‑Means, DBSCAN).
  • Na performance dos modelos supervisionados (RF, XGBoost, MLP, LSTM).

5) Avaliação técnica
- Incluir métricas adequadas para:
  • Séries temporais / regressão: MAE, MSE, RMSE (e eventualmente MAPE).
  • Clustering: silhouette score, número de clusters, proporção de ruído (DBSCAN) e interpretação qualitativa dos perfis.
- Comparar sempre com a baseline “igual à semana anterior”.

6) Entrega e forma
- Projeto desenvolvido em Python Notebooks.
- Entregar:
  • PDF com o relatório final (seguindo CRISP‑DM).
  • Notebooks com o código.
  • Amostras de datasets intermédios relevantes para correr os notebooks.
- Haverá apresentação oral e discussão, onde todas as decisões e blocos de código devem ser explicáveis.


[PARTE 2 – PLANO PASSO A PASSO PARA FAZER O PROJETO]

1. Estrutura de pastas e ficheiros

Criar uma estrutura deste género:

project_root/
  data/
    raw/
      D4Maia.csv
    intermediate/
      d4maia_clean.parquet
      d4maia_series_per_cpe.parquet
      d4maia_cpe_features.parquet
      d4maia_ts_train_test_index.csv
      d4maia_cpe_clusters.csv
      d4maia_ts_results.csv
      d4maia_feature_models_results.csv
  notebooks/
    01_business_data_understanding.ipynb
    02_data_preparation_feature_engineering.ipynb
    03_clustering_kmeans_dbscan.ipynb
    04_timeseries_ARIMA_LSTM.ipynb
    05_supervised_features_RF_XGB_MLP.ipynb
    06_normalization_and_comparisons.ipynb
  src/
    data_loading.py
    preprocessing.py
    feature_engineering.py
    clustering_models.py
    timeseries_models.py
    supervised_models.py
    evaluation.py
  reports/
    IAA_Project_Report.pdf
  slides/
    IAA_Project_Presentation.pptx
  environment.yml ou requirements.txt
  README.md


2. Fase CRISP‑DM – Business Understanding (notebook 01)

No ficheiro notebooks/01_business_data_understanding.ipynb:

2.1. Enquadrar o problema:
- Explicar o contexto: Município da Maia, consumo de energia em edifícios de serviços, leituras de 15 em 15 minutos.
- Explicar o objetivo de negócio: perceber perfis de consumo e capacidade de previsão.

2.2. Definir objetivos de negócio:
- Identificar tipos de consumidores (clusters de CPE).
- Avaliar a capacidade de prever consumos de uma semana à frente.

2.3. Traduzir em objetivos de dados/modelos:
- Clustering com K‑Means/DBSCAN + caracterização de perfis.
- Modelos ARIMA/LSTM e RF/XGBoost/MLP com baseline “semana anterior”.
- Experiência explícita sobre o efeito da normalização.


3. Fase CRISP‑DM – Data Understanding (notebooks 01 e 02)

No final do 01_business_data_understanding.ipynb e início do 02_data_preparation_feature_engineering.ipynb:

3.1. Carregar dados (src/data_loading.py):
- Implementar uma função load_d4maia(path) que:
  • lê data/raw/D4Maia.csv com pandas.read_csv
  • converte a coluna hora para datetime
  • ordena o DataFrame por CPE e hora
- No notebook, chamar essa função e guardar o DataFrame como df.

3.2. Inspeção inicial:
- df.info(), df.describe()
- Número de CPEs distintos.
- Distribuição do número de registos por CPE.
- Verificar missing values, valores negativos, outliers extremos.

3.3. Exploração gráfica:
- Histogramas/KDE de:
  • DadosDeConsumo
  • PotAtiva
  • PotReactIndut
  • PotReactCapac
- Matriz de correlação entre variáveis numéricas.
- Algumas séries temporais de exemplo:
  • Escolher 3–5 CPEs com padrões diferentes e fazer gráficos de linha (hora vs DadosDeConsumo).

3.4. Conclusões desta fase:
- Notar relações fortes (por exemplo entre PotAtiva e DadosDeConsumo).
- Identificar CPEs com poucos dados (candidatos a exclusão em fases avançadas).
- Guardar, se necessário, uma versão limpa:
  • data/intermediate/d4maia_clean.parquet


4. Fase CRISP‑DM – Data Preparation (notebook 02)

4.1. Preparar séries temporais por CPE

No notebooks/02_data_preparation_feature_engineering.ipynb e src/preprocessing.py:

- A partir de df (ou d4maia_clean), criar:
  • Um DataFrame long com colunas: CPE, hora, DadosDeConsumo, PotAtiva
- Garantir que:
  • Está ordenado por CPE e hora.
- Guardar em:
  • data/intermediate/d4maia_series_per_cpe.parquet

4.1.1. Filtrar CPEs curtos:
- Calcular, para cada CPE, número de registos.
- Definir um limiar mínimo (por exemplo, número de pontos equivalente a X semanas).
- Criar lista de CPEs válidos e guardar (por exemplo num ficheiro auxiliar ou em memória).

4.1.2. Definir splits treino/teste (70% / 30%):
- Para cada CPE válido:
  • ordenar por hora
  • calcular o índice temporal que marca os 70% iniciais
  • guardar o timestamp de split
- Criar ficheiro:
  • data/intermediate/d4maia_ts_train_test_index.csv
  com colunas (CPE, split_timestamp)

4.2. Preparar features agregadas por CPE

Ainda no notebook 02, com funções em src/feature_engineering.py:

4.2.1. Criar colunas auxiliares:
- hora_do_dia = hour(hora)
- dia_da_semana = weekday(hora)
- is_weekend = dia_da_semana >= 5

4.2.2. Definir features:
Exemplos de features para cada CPE:
- avg_daily_consumption
- max_daily_consumption
- avg_afternoon_peak_value (picos entre, por exemplo, 12h e 18h)
- avg_daily_peak_time (hora média do pico diário)
- avg_time_below_50%_consumption (proporção de amostras abaixo de 50% do pico típico)
- consumo médio em dias úteis vs fins de semana
- consumo médio por hora do dia (24 valores ou agregações em janelas maiores)

4.2.3. Calcular e guardar:
- Usar groupby("CPE") para calcular estas estatísticas.
- Guardar o resultado em:
  • data/intermediate/d4maia_cpe_features.parquet
  (uma linha por CPE, colunas = features + CPE)


5. Fase CRISP‑DM – Modeling, Experiência 1: Clustering (notebook 03)

No notebooks/03_clustering_kmeans_dbscan.ipynb, com apoio de src/clustering_models.py:

5.1. Carregar data/intermediate/d4maia_cpe_features.parquet.

5.2. Selecionar features:
- Retirar coluna CPE e quaisquer IDs.
- Tratar outliers se necessário (por exemplo, transformações log, winsorização).

5.3. K‑Means sem normalização:
- Aplicar KMeans para k de 2 a 10.
- Para cada k:
  • obter inertia (inércia)
  • calcular silhouette score
- Escolher k com base no gráfico do “cotovelo” e no silhouette.

5.4. K‑Means com normalização:
- Aplicar StandardScaler ou MinMaxScaler às features.
- Repetir experiência K‑Means com o mesmo intervalo de k.
- Comparar métricas com a versão sem normalização.

5.5. DBSCAN:
- Trabalhar em dados normalizados.
- Testar vários (eps, min_samples):
  • por exemplo, eps em {0.3, 0.5, 0.7} e min_samples em {5, 10, 20}
- Observar número de clusters e fração de pontos marcados como ruído.

5.6. Caracterização dos clusters:
- Para cada cluster:
  • calcular médias das principais features
  • interpretar perfis (diurno, noturno, 24/7, etc.)
- Ver se há CPEs muito estranhos (outliers) que podem ser relevantes para o município.

5.7. Guardar resultados:
- Criar data/intermediate/d4maia_cpe_clusters.csv com colunas:
  • CPE
  • cluster_kmeans (para o k escolhido)
  • cluster_dbscan (ou -1 para ruído)


6. Fase CRISP‑DM – Modeling, Experiência 2(a): Séries temporais (notebook 04)

No notebooks/04_timeseries_ARIMA_LSTM.ipynb, com funções em src/timeseries_models.py:

6.1. Carregar:
- data/intermediate/d4maia_series_per_cpe.parquet
- data/intermediate/d4maia_ts_train_test_index.csv

6.2. Definir baseline “semana anterior”:
- Cada leitura é feita a cada 15 minutos → 96 pontos por dia, 672 por semana.
- Para cada CPE e para cada ponto do conjunto de teste:
  • prever valor = valor na mesma hora exata na semana anterior (posição deslocada 672 passos para trás, se existir).
- Calcular métricas por CPE:
  • MAE, RMSE

6.3. Modelos ARIMA:
- Selecionar um subconjunto de CPEs (por exemplo 5–10) representativos.
- Para cada um:
  • treinar ARIMA na parte de treino (70%)
  • gerar previsões sobre a parte de teste (30%)
- Comparar MAE e RMSE com a baseline.
- Opcional: usar auto_arima para escolher (p, d, q), ou fazer tentativa manual.

6.4. Modelos LSTM:
- Normalizar cada série individualmente (guardar média e desvio padrão ou min/max).
- Criar janelas de input:
  • exemplo: usar últimos 7 dias (7×96 pontos) como input para prever o próximo dia ou ponto.
- Construir um modelo LSTM simples em Keras:
  • camadas LSTM → Dense(1)
- Treinar usando dados de treino de vários CPEs (opcional) ou um CPE de cada vez.
- Avaliar no conjunto de teste:
  • desnormalizar previsões
  • calcular MAE e RMSE
- Comparar com baseline e ARIMA.

6.5. Guardar resultados:
- Criar data/intermediate/d4maia_ts_results.csv com colunas:
  • CPE
  • model (baseline, ARIMA, LSTM)
  • MAE
  • RMSE


7. Fase CRISP‑DM – Modeling, Experiência 2(b): Modelos com features (notebook 05)

No notebooks/05_supervised_features_RF_XGB_MLP.ipynb, com auxílio de src/supervised_models.py:

7.1. Definir target:
- Exemplo: consumo médio da semana seguinte para cada CPE, ou consumo numa determinada data/hora da semana seguinte.
- O ponto chave: todas as features usadas como input têm de ser calculadas com dados pelo menos 1 semana mais antigos.

7.2. Construir dataset supervisionado:
- Para cada CPE e para cada “instante alvo”:
  • construir um vetor de features agregadas até t−7 dias
  • definir y = consumo previsto entre t e t+7 dias (ou num instante específico na janela).
- Juntar todos os CPEs num único DataFrame de treino/teste.

7.3. Definir divisão treino/teste:
- Usar sempre cortes temporais (não baralhar aleatoriamente no tempo):
  • por exemplo, usar períodos mais antigos para treino e mais recentes para teste.

7.4. Modelos:
- RandomForestRegressor (sklearn)
- XGBRegressor (xgboost)
- MLPRegressor (sklearn)
- Testar versões:
  • sem normalização
  • com normalização (StandardScaler/MinMaxScaler) – sobretudo para o MLP.

7.5. Avaliação:
- Calcular MAE, RMSE (e opcionalmente MAPE) para cada modelo.
- Comparar com a baseline “semana anterior” adaptada a este alvo (por exemplo, consumo médio da semana anterior).
- Comparar também com resultados de ARIMA/LSTM para um conjunto de CPEs comum.

7.6. Guardar resultados:
- Criar data/intermediate/d4maia_feature_models_results.csv com colunas do tipo:
  • model (RF, XGB, MLP, baseline)
  • métricas globais e/ou por CPE (dependendo de como organizares o dataset)


8. Fase CRISP‑DM – Evaluation e normalização (notebook 06)

No notebooks/06_normalization_and_comparisons.ipynb, com apoio de src/evaluation.py:

8.1. Comparar clusters com e sem normalização:
- Mostrar tabela/gráfico com silhouette score por k.
- Discutir alterações no número de clusters, distribuição e interpretação.

8.2. Comparar modelos de séries:
- Usar data/intermediate/d4maia_ts_results.csv.
- Fazer boxplots ou tabelas de MAE/RMSE por modelo.
- Concluir se ARIMA ou LSTM melhoram significativamente face à baseline e em que situações.

8.3. Comparar modelos com features:
- Usar data/intermediate/d4maia_feature_models_results.csv.
- Mostrar erros (MAE, RMSE) dos modelos RF, XGB, MLP vs baseline.

8.4. Comparar “séries diretas” vs “features agregadas”:
- Discutir vantagens e desvantagens:
  • complexidade
  • capacidade de generalização
  • interpretação.

8.5. Ligar resultados ao contexto de negócio:
- Indicar que clusters são mais previsíveis.
- Indicar se as previsões atingem um nível de erro que possa ser útil para planeamento de energia.


9. Relatório final e apresentação

9.1. Relatório (IAA_Project_Report.pdf):
- Seguir a estrutura CRISP‑DM:
  • Business Understanding
  • Data Understanding
  • Data Preparation
  • Modeling
  • Evaluation
- Incluir figuras e tabelas geradas nos notebooks.
- Explicar e justificar todas as escolhas (features, normalização, modelos, métricas).

9.2. Apresentação (IAA_Project_Presentation.pptx):
- Slides sugeridos:
  • Contexto e objetivos
  • Dataset e CRISP‑DM
  • Data Understanding (principais observações)
  • Clustering (métodos, resultados, interpretação de perfis)
  • Modelos de séries temporais (ARIMA, LSTM, baseline)
  • Modelos com features (RF, XGB, MLP, baseline)
  • Efeito da normalização
  • Conclusões e trabalho futuro


[FIM DO FICHEIRO]
