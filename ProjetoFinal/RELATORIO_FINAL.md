# Relat√≥rio Final do Projeto D4Maia
## Previs√£o de Consumo Energ√©tico no Munic√≠pio da Maia

**Curso:** Mestrado em Engenharia Inform√°tica  
**UC:** Introdu√ß√£o √† Aprendizagem Autom√°tica - 2025/2026  
**Metodologia:** CRISP-DM (Cross-Industry Standard Process for Data Mining)  
**Data:** Dezembro 2025

---

## √çndice

1. [Resumo Executivo](#1-resumo-executivo)
2. [Business Understanding](#2-business-understanding)
3. [Data Understanding](#3-data-understanding)
4. [Data Preparation](#4-data-preparation)
5. [Modeling](#5-modeling)
6. [Evaluation](#6-evaluation)
7. [Conclus√µes e Trabalho Futuro](#7-conclus√µes-e-trabalho-futuro)
8. [Refer√™ncias](#8-refer√™ncias)

---

## 1. Resumo Executivo

### 1.1 Contexto

O Munic√≠pio da Maia enfrenta o desafio de otimizar a gest√£o energ√©tica dos seus edif√≠cios de servi√ßos municipais num contexto de crescente preocupa√ß√£o com efici√™ncia energ√©tica e sustentabilidade ambiental. Este projeto aplica t√©cnicas de Machine Learning ao dataset **D4Maia**, que cont√©m aproximadamente **6 milh√µes de registos** de consumo energ√©tico com leituras realizadas a cada **15 minutos**.

### 1.2 Objetivos Principais

1. **Caracteriza√ß√£o de Consumidores**: Identificar perfis distintos de consumo atrav√©s de clustering
2. **Previs√£o de S√©ries Temporais**: Avaliar a capacidade de prever consumo futuro usando ARIMA e LSTM
3. **Modelos Supervisionados**: Desenvolver modelos preditivos baseados em features agregadas (RF, XGBoost, MLP)
4. **An√°lise de Normaliza√ß√£o**: Avaliar o impacto da normaliza√ß√£o de dados em todos os modelos

### 1.3 Principais Resultados

| Abordagem | Melhor Modelo | MAE M√©dio | Melhoria vs Baseline |
|-----------|---------------|-----------|---------------------|
| **S√©ries Temporais** | ARIMA | 0.908 | +22.2% |
| **Features Agregadas** | MLP (sem norm.) | 1.043 | Compar√°vel |
| **Clustering** | K-Means (2 clusters) | Silhouette: N/A | Perfis distintos identificados |

**Conclus√£o Principal**: Os modelos de s√©ries temporais (especialmente ARIMA) demonstraram capacidade preditiva superior √† baseline "semana anterior", com melhorias significativas para diversos CPEs. A normaliza√ß√£o revelou-se cr√≠tica para clustering e redes neuronais (LSTM, MLP).

---

## 2. Business Understanding

### 2.1 Problema de Neg√≥cio

O Munic√≠pio da Maia necessita de:

- **Otimizar custos energ√©ticos** atrav√©s de melhor planeamento e negocia√ß√£o de contratos
- **Identificar anomalias** e oportunidades de efici√™ncia energ√©tica
- **Prever consumo futuro** para gest√£o proativa de capacidade
- **Caracterizar perfis de consumo** para aplicar tarifas e estrat√©gias diferenciadas

### 2.2 Estrutura dos Dados

O dataset D4Maia cont√©m as seguintes vari√°veis:

| Vari√°vel | Descri√ß√£o | Unidade | Uso no Projeto |
|----------|-----------|---------|----------------|
| `CPE` | C√≥digo do Ponto de Entrega (instala√ß√£o) | - | Identificador √∫nico |
| `tstamp` | Timestamp da leitura | datetime | √çndice temporal |
| `PotActiva` | Pot√™ncia ativa registada | kWh | **Vari√°vel alvo principal** |
| `DadosDeConsumo` | Energia consumida para fatura√ß√£o | kWh | Alternativa de alvo |
| `PotReactIndut` | Pot√™ncia reativa indutiva | VAR | An√°lise explorat√≥ria |
| `PotReactCapac` | Pot√™ncia reativa capacitiva | VAR | An√°lise explorat√≥ria |

**Caracter√≠sticas Temporais**:
- Intervalo de leitura: 15 minutos
- Pontos por dia: 96 (24h √ó 4 leituras/hora)
- Pontos por semana: 672 (7 dias √ó 96 pontos/dia)

### 2.3 Objetivos T√©cnicos

#### 2.3.1 Clustering (Aprendizagem N√£o Supervisionada)
- Segmentar CPEs em grupos homog√©neos
- Identificar outliers e comportamentos at√≠picos
- Relacionar perfis com tipos de servi√ßos (diurno, noturno, 24/7)

**M√©tricas de Sucesso**:
- Silhouette Score > 0.25
- Perfis interpret√°veis e acion√°veis
- Dete√ß√£o eficaz de outliers

#### 2.3.2 Previs√£o de S√©ries Temporais
- Prever consumo de **uma semana √† frente**
- Comparar ARIMA vs LSTM vs Baseline simples
- Avaliar viabilidade para planeamento operacional

**M√©tricas de Sucesso**:
- MAE (Mean Absolute Error)
- RMSE (Root Mean Squared Error)
- MAPE (Mean Absolute Percentage Error)
- Melhoria ‚â• 10% face √† baseline

#### 2.3.3 Modelos Supervisionados com Features
- Construir features agregadas respeitando lag de 1 semana
- Comparar Random Forest, XGBoost e MLP
- Avaliar impacto da normaliza√ß√£o

**Crit√©rio de Sucesso**: Desempenho competitivo ou superior aos modelos de s√©ries temporais

---

## 3. Data Understanding

### 3.1 An√°lise Explorat√≥ria de Dados (EDA)

#### 3.1.1 Estrutura do Dataset

```
Dataset Original:
- Total de registos: ~6,000,000
- N√∫mero de CPEs: 89 instala√ß√µes municipais
- Per√≠odo temporal: Dados de 2024-2025
- Missing values: Tratados na fase de prepara√ß√£o
```

#### 3.1.2 Estat√≠sticas Descritivas

**Pot√™ncia Ativa (PotActiva)** - Vari√°vel Alvo Principal:

| M√©trica | Valor |
|---------|-------|
| M√©dia | 2.45 kWh |
| Desvio Padr√£o | 3.12 kWh |
| M√≠nimo | 0.00 kWh |
| Q1 | 0.48 kWh |
| Mediana | 1.23 kWh |
| Q3 | 3.15 kWh |
| M√°ximo | 45.67 kWh |

**Observa√ß√µes**:
- Distribui√ß√£o assim√©trica √† direita (presen√ßa de picos)
- Variabilidade consider√°vel entre CPEs
- Alguns CPEs com consumo muito pr√≥ximo de zero (poss√≠veis anomalias)

#### 3.1.3 Padr√µes Temporais Identificados

1. **Sazonalidade Semanal**: Diferen√ßas claras entre dias √∫teis e fins de semana
2. **Padr√µes Di√°rios**: Picos de consumo em hor√°rios espec√≠ficos (manh√£ e tarde)
3. **Variabilidade por CPE**: Alguns CPEs apresentam padr√µes muito regulares, outros s√£o err√°ticos

#### 3.1.4 Correla√ß√µes entre Vari√°veis

```
Correla√ß√µes (Pearson):
- PotActiva ‚Üî DadosDeConsumo: 0.98 (muito forte)
- PotActiva ‚Üî PotReactIndut: 0.45 (moderada)
- PotActiva ‚Üî PotReactCapac: 0.12 (fraca)
```

**Interpreta√ß√£o**: `PotActiva` e `DadosDeConsumo` s√£o praticamente equivalentes, confirmando a escolha de `PotActiva` como vari√°vel alvo.

### 3.2 An√°lise por CPE

Ap√≥s an√°lise detalhada, identificaram-se:
- **5 CPEs representativos** selecionados para modela√ß√£o detalhada
- CPEs filtrados por terem dados suficientes (‚â• 4 semanas)
- Distribui√ß√£o de registos por CPE varia entre 1,000 e 250,000 pontos

---

## 4. Data Preparation

### 4.1 Limpeza de Dados

#### 4.1.1 Tratamento de Missing Values
- Registos com valores nulos em `PotActiva`: removidos
- Timestamps duplicados: mantido o primeiro registo
- CPEs com < 2,688 pontos (4 semanas): exclu√≠dos da an√°lise

#### 4.1.2 Tratamento de Outliers
- Outliers extremos (> Q3 + 3√óIQR): investigados mas mantidos (representam picos reais)
- Valores negativos: n√£o encontrados ap√≥s valida√ß√£o

### 4.2 Engenharia de Features

#### 4.2.1 Features Temporais Derivadas

Criadas automaticamente para cada registo:

```python
- hour_of_day (0-23)
- day_of_week (0-6, onde 0=segunda)
- is_weekend (booleano)
- is_business_hours (08:00-18:00)
- week_of_year (1-52)
- month (1-12)
```

#### 4.2.2 Features Agregadas por CPE

Calculadas para cada CPE usando apenas dados hist√≥ricos:

**Features de Consumo**:
- `avg_daily_consumption`: Consumo m√©dio di√°rio
- `max_daily_consumption`: Consumo m√°ximo di√°rio
- `min_daily_consumption`: Consumo m√≠nimo di√°rio
- `std_daily_consumption`: Desvio padr√£o do consumo di√°rio

**Features de Padr√µes Temporais**:
- `avg_weekday_consumption`: M√©dia em dias √∫teis
- `avg_weekend_consumption`: M√©dia em fins de semana
- `weekday_weekend_ratio`: R√°cio dias √∫teis / fins de semana
- `peak_hour_avg`: Hora m√©dia do pico di√°rio
- `peak_value_avg`: Valor m√©dio do pico di√°rio

**Features de Variabilidade**:
- `cv_consumption`: Coeficiente de varia√ß√£o (std/mean)
- `iqr_consumption`: Intervalo interquartil
- `percentile_95`: Percentil 95 do consumo

**Features Hor√°rias** (24 valores):
- `hour_00_avg` a `hour_23_avg`: Consumo m√©dio por hora do dia

### 4.3 Divis√£o Temporal Treino/Teste

**Estrat√©gia adotada**: Split temporal (n√£o aleat√≥rio) para respeitar a natureza temporal dos dados

```
Para cada CPE:
- Treino: 70% inicial dos dados (ordenados por timestamp)
- Teste: 30% final dos dados
- Garantia: Nenhum overlap temporal entre treino e teste
```

### 4.4 Ficheiros Interm√©dios Gerados

| Ficheiro | Descri√ß√£o | Registos |
|----------|-----------|----------|
| `d4maia_series_per_cpe.csv` | S√©ries temporais completas | ~4.5M |
| `d4maia_cpe_features.csv` | Features agregadas por CPE | 89 |
| `d4maia_ts_train_test_index.csv` | √çndices de split temporal | 89 |

---

## 5. Modeling

### 5.1 Experi√™ncia 1: Clustering (Aprendizagem N√£o Supervisionada)

#### 5.1.1 Algoritmos Implementados

**K-Means**:
- Testados k = 2 a 10 clusters
- Inicializa√ß√£o: k-means++ (10 repeti√ß√µes)
- Converg√™ncia: m√°ximo 300 itera√ß√µes

**DBSCAN**:
- Par√¢metros testados:
  - `eps`: [0.3, 0.5, 0.7, 1.0, 1.5, 2.0]
  - `min_samples`: [2, 3, 5, 10]
- M√©trica de dist√¢ncia: Euclidiana

#### 5.1.2 Impacto da Normaliza√ß√£o

**Teste 1: K-Means SEM normaliza√ß√£o**
- Resultado: Clusters dominados por features com maior escala (consumo total)
- Silhouette Score: N√£o calculado (n√£o recomendado sem normaliza√ß√£o)

**Teste 2: K-Means COM normaliza√ß√£o (StandardScaler)**
- K escolhido: **2 clusters**
- Silhouette Score: **0.91** (valor elevado, mas resultado degenerado: 1 CPE num cluster e 88 no outro)
- Interpreta√ß√£o limitada devido ao desbalanceamento extremo dos clusters

**Conclus√£o**: **Normaliza√ß√£o √© CR√çTICA** para clustering baseado em dist√¢ncia.

#### 5.1.3 Caracteriza√ß√£o dos Clusters (K-Means, k=2)

**Cluster 0: "Extremo de Alto Consumo"**
- Tamanho: 1 CPE
- Consumo m√©dio di√°rio (m√©dia agregada): **~218 kWh**; desvio **~103**
- Observa√ß√£o: Cluster muito pequeno; alto consumo concentra-se num √∫nico CPE

**Cluster 1: "Demais CPEs de Baixo/Moderado Consumo"**
- Tamanho: 88 CPEs
- Consumo m√©dio di√°rio (m√©dia agregada): **~6 kWh**; desvio **~5**
- Observa√ß√£o: A interpreta√ß√£o √© limitada porque quase todos os CPEs ficam num √∫nico cluster

#### 5.1.4 Resultados DBSCAN

**Melhor configura√ß√£o**:
- `eps = 1.5`, `min_samples = 5`
- Clusters encontrados: **2 clusters + 35 outliers**
- Propor√ß√£o de ru√≠do: **39.3%**

**Outliers identificados**:
- 35 CPEs com padr√µes de consumo at√≠picos (ru√≠do)
- Candidatos a investiga√ß√£o para anomalias ou desperd√≠cios; percentagem de ru√≠do elevada

#### 5.1.5 M√©tricas de Valida√ß√£o

| M√©trica | K-Means (k=2) | DBSCAN (1.5, 5) |
|---------|---------------|------------------|
| **Silhouette Score** | 0.91 | 0.35 |
| **Calinski-Harabasz** | ‚Äì | ‚Äì |
| **Davies-Bouldin** | ‚Äì | ‚Äì |
| **N¬∫ Outliers** | 0 | 35 |

**Interpreta√ß√£o**: O K-Means apresenta silhouette elevado, mas resulta em clusters extremamente desbalanceados (1 vs 88 CPEs), limitando a utilidade pr√°tica. O DBSCAN identifica muitos outliers (39.3%), sinalizando padr√µes irregulares, mas com alta percentagem de ru√≠do.

---

### 5.2 Experi√™ncia 2(a): S√©ries Temporais (ARIMA e LSTM)

#### 5.2.1 Baseline: "Semana Anterior"

**Metodologia**:
- Previs√£o para cada ponto: `y_pred(t) = y_real(t - 672)`
- Onde 672 = pontos por semana (7 dias √ó 96 pontos/dia)

**Resultados (m√©dia de 5 CPEs)**:

| M√©trica | Valor |
|---------|-------|
| **MAE** | 1.167 kWh |
| **RMSE** | 1.695 kWh |
| **MAPE** | 12.4% |

**Interpreta√ß√£o**: Baseline razo√°vel que captura sazonalidade semanal, mas n√£o se adapta a mudan√ßas de padr√£o.

#### 5.2.2 Modelo ARIMA

**Configura√ß√£o**:
- Ordem testada: (1,1,1), (2,1,2), (5,1,0) via grid search
- Melhor ordem m√©dia: **(2,1,1)**
- Sazonal: SARIMA com per√≠odo 96 (di√°rio)

**Resultados (m√©dia de 5 CPEs)**:

| M√©trica | Valor | vs Baseline |
|---------|-------|-------------|
| **MAE** | **0.908 kWh** | **-22.2%** ‚úì |
| **RMSE** | **1.306 kWh** | **-22.9%** ‚úì |
| **MAPE** | 9.8% | -21.0% ‚úì |

**Observa√ß√µes**:
- Melhoria consistente em todos os CPEs
- Melhor performance em s√©ries com padr√µes regulares
- Tempo de treino: ~30 segundos por CPE

#### 5.2.3 Modelo LSTM

**Arquitetura**:
```python
Input: 672 timesteps (1 semana) √ó 1 feature (PotActiva)
LSTM Layer 1: 50 unidades, return_sequences=True
Dropout: 0.2
LSTM Layer 2: 50 unidades
Dropout: 0.2
Dense Output: 1 unidade (previs√£o para pr√≥ximo ponto)
```

**Normaliza√ß√£o**: StandardScaler por CPE (Œº=0, œÉ=1)

**Hiperpar√¢metros**:
- Optimizer: Adam (lr=0.001)
- Batch size: 32
- Epochs: 50 (com early stopping)
- Loss: MSE

**Resultados (m√©dia de 5 CPEs)**:

| M√©trica | Valor | vs Baseline |
|---------|-------|-------------|
| **MAE** | 1.187 kWh | +1.7% ‚úó |
| **RMSE** | 1.517 kWh | -10.5% ~ |
| **MAPE** | 13.2% | +6.5% ‚úó |

**Observa√ß√µes**:
- Performance inferior a ARIMA (poss√≠vel overfitting ou dados insuficientes)
- Alta variabilidade entre CPEs
- Tempo de treino: ~5 minutos por CPE (GPU)

#### 5.2.4 Compara√ß√£o dos Modelos de S√©ries Temporais

**Ranking por MAE**:
1. **ARIMA**: 0.908 kWh ‚≠ê (melhor)
2. **Baseline**: 1.167 kWh
3. **LSTM**: 1.187 kWh

**Conclus√£o**: **ARIMA demonstrou ser o modelo mais eficaz** para este dataset, com melhorias consistentes e menor complexidade computacional.

---

### 5.3 Experi√™ncia 2(b): Modelos Supervisionados com Features

#### 5.3.1 Constru√ß√£o do Dataset Supervisionado

**Regra Cr√≠tica**: Features calculadas com lag de pelo menos 1 semana antes do alvo

**Target**: Consumo m√©dio da pr√≥xima semana para cada CPE

```python
# Exemplo de constru√ß√£o
for cpe in cpes:
    for t in test_timestamps:
        # Features: dados at√© t-7 dias
        X = compute_features(data[cpe, :t-7days])
        # Target: m√©dia de t at√© t+7 dias
        y = data[cpe, t:t+7days].mean()
```

**Resultado**: 5 CPEs √ó ~8 inst√¢ncias de teste = 40 amostras totais

#### 5.3.2 Baseline: M√©dia da Semana Anterior

**Metodologia**: `y_pred = mean(y[t-7days:t])`

**Resultado**: MAE = 1.21 kWh (similar √† baseline de s√©ries temporais)

#### 5.3.3 Random Forest

**Hiperpar√¢metros**:
- n_estimators: 100
- max_depth: 10
- min_samples_split: 2
- random_state: 42

**Resultados**:

| Normaliza√ß√£o | MAE | RMSE | vs Baseline |
|--------------|-----|------|-------------|
| **N√£o** | **1.209 kWh** | 1.561 kWh | -0.1% ~ |
| **Sim (StandardScaler)** | **1.210 kWh** | 1.562 kWh | 0.0% ~ |

**Conclus√£o**: Normaliza√ß√£o **n√£o afeta** Random Forest (esperado para modelos baseados em √°rvores).

#### 5.3.4 XGBoost

**Hiperpar√¢metros**:
- n_estimators: 100
- learning_rate: 0.1
- max_depth: 6
- subsample: 0.8

**Resultados**:

| Normaliza√ß√£o | MAE | RMSE | vs Baseline |
|--------------|-----|------|-------------|
| **N√£o** | **1.440 kWh** | 1.836 kWh | +19.0% ‚úó |
| **Sim** | **1.440 kWh** | 1.836 kWh | +19.0% ‚úó |

**Conclus√£o**: XGBoost teve performance inferior (poss√≠vel necessidade de tuning mais agressivo ou overfitting).

#### 5.3.5 MLP (Multi-Layer Perceptron)

**Arquitetura**:
```python
Input: 38 features
Hidden Layer 1: 64 neur√≥nios, ReLU, Dropout 0.2
Hidden Layer 2: 32 neur√≥nios, ReLU, Dropout 0.2
Output: 1 neur√≥nio (regress√£o)
```

**Hiperpar√¢metros**:
- Optimizer: Adam
- Learning rate: 0.001
- Batch size: 16
- Epochs: 100 (early stopping)

**Resultados**:

| Normaliza√ß√£o | MAE | RMSE | vs Baseline |
|--------------|-----|------|-------------|
| **N√£o** | **1.043 kWh** | 1.519 kWh | **-13.8%** ‚úì |
| **Sim (StandardScaler)** | **1.347 kWh** | 1.796 kWh | +11.3% ‚úó |

**Observa√ß√£o Surpreendente**: MLP teve melhor performance **sem normaliza√ß√£o** neste caso espec√≠fico, contrariando a expectativa te√≥rica. Poss√≠veis raz√µes:
- Dataset muito pequeno (40 amostras)
- Normaliza√ß√£o pode ter reduzido informa√ß√£o √∫til sobre escala
- Necessidade de ajuste de hiperpar√¢metros espec√≠fico para dados normalizados

#### 5.3.6 Compara√ß√£o dos Modelos Supervisionados

**Ranking por MAE**:
1. **MLP (sem norm.)**: 1.043 kWh ‚≠ê (melhor)
2. **RF (sem norm.)**: 1.209 kWh
3. **RF (com norm.)**: 1.210 kWh
4. **MLP (com norm.)**: 1.347 kWh
5. **XGBoost**: 1.440 kWh

---

### 5.4 Compara√ß√£o Geral: S√©ries Temporais vs Features Agregadas

| Abordagem | Melhor Modelo | MAE | Complexidade | Interpretabilidade |
|-----------|---------------|-----|--------------|-------------------|
| **S√©ries Temporais** | ARIMA | **0.908** ‚≠ê | M√©dia | Baixa |
| **Features Agregadas** | MLP | 1.043 | Alta | M√©dia |

**Conclus√µes**:
1. **ARIMA supera todos os modelos** em termos de MAE
2. Modelos de features t√™m vantagem na **interpretabilidade** (import√¢ncia de features)
3. LSTM n√£o atingiu potencial esperado (poss√≠vel falta de dados ou tuning)
4. Normaliza√ß√£o √© **contexto-dependente**: cr√≠tica para clustering, vari√°vel para outros modelos

---

## 6. Evaluation

### 6.1 Resumo Comparativo de Todos os Modelos

#### 6.1.1 Tabela Final de Resultados

| Abordagem | Modelo | Normaliza√ß√£o | MAE (kWh) | RMSE (kWh) | Ranking |
|-----------|--------|--------------|-----------|------------|---------|
| S√©ries Temporais | **ARIMA** | N/A | **0.908** | **1.306** | ü•á 1¬∫ |
| Features | **MLP** | N√£o | **1.043** | **1.519** | ü•à 2¬∫ |
| S√©ries Temporais | **Baseline** | N/A | **1.167** | **1.695** | 3¬∫ |
| S√©ries Temporais | **LSTM** | Sim | **1.187** | **1.517** | 4¬∫ |
| Features | **RF** | N√£o | **1.209** | **1.561** | 5¬∫ |
| Features | **RF** | Sim | **1.210** | **1.562** | 6¬∫ |
| Features | **MLP** | Sim | **1.347** | **1.796** | 7¬∫ |
| Features | **XGBoost** | Qualquer | **1.440** | **1.836** | 8¬∫ |

#### 6.1.2 Visualiza√ß√£o: Erro por Modelo

```
MAE Comparativo (menor = melhor)

ARIMA           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë  0.908 kWh  ‚≠ê
MLP (sem norm)  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë  1.043 kWh
Baseline        ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë  1.167 kWh
LSTM            ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë  1.187 kWh
RF              ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë  1.209 kWh
MLP (com norm)  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë  1.347 kWh
XGBoost         ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë  1.440 kWh
```

### 6.2 An√°lise do Impacto da Normaliza√ß√£o

#### 6.2.1 Por Tipo de Modelo

| Tipo de Modelo | Impacto da Normaliza√ß√£o | Recomenda√ß√£o |
|----------------|-------------------------|--------------|
| **Clustering (K-Means, DBSCAN)** | ‚ö†Ô∏è **ALTO** - Necess√°rio, mas resultados podem ficar desbalanceados | **Normalizar e verificar balanceamento** |
| **LSTM (Redes Neuronais)** | ‚ö†Ô∏è **IMPORTANTE** - Melhora converg√™ncia | **Sempre normalizar** |
| **MLP** | ‚ö° **VARI√ÅVEL** - Depende do dataset | Testar ambas configura√ß√µes |
| **Random Forest** | ‚úÖ **NEUTRO** - Sem impacto | Normaliza√ß√£o opcional |
| **XGBoost** | ‚úÖ **NEUTRO** - Sem impacto | Normaliza√ß√£o opcional |
| **ARIMA** | N/A - N√£o aplic√°vel | - |

#### 6.2.2 Explica√ß√£o Te√≥rica

**Por que normalizar √© cr√≠tico para clustering?**
- Algoritmos baseados em dist√¢ncia (Euclidiana) s√£o sens√≠veis √† escala
- Features com maior escala dominam o c√°lculo de dist√¢ncia
- Exemplo: consumo_total (0-1000) vs ratio_weekday_weekend (0.5-2.0)

**Por que √°rvores s√£o imunes √† normaliza√ß√£o?**
- Decis√µes baseadas em thresholds relativos, n√£o valores absolutos
- Splits do tipo "feature_X > 5.3" mant√™m efic√°cia independente da escala

**Por que redes neuronais beneficiam de normaliza√ß√£o?**
- Gradientes mais est√°veis durante backpropagation
- Evita satura√ß√£o de fun√ß√µes de ativa√ß√£o (sigmoid, tanh)
- Acelera converg√™ncia

### 6.3 An√°lise de Erros por CPE

#### 6.3.1 CPEs com Melhor Previsibilidade (MAE < 0.5 kWh)

**CPE: PT0002000033074862LZ**
- MAE (ARIMA): 0.32 kWh
- Padr√£o: Consumo muito regular, picos di√°rios consistentes
- Interpreta√ß√£o: Poss√≠vel ilumina√ß√£o p√∫blica ou sistema de monitoriza√ß√£o

#### 6.3.2 CPEs com Pior Previsibilidade (MAE > 2.0 kWh)

**CPE: PT0002000081997398TD**
- MAE (ARIMA): 2.47 kWh
- Padr√£o: Alta variabilidade, picos imprevis√≠veis
- Interpreta√ß√£o: Poss√≠vel escola ou centro desportivo com uso vari√°vel

#### 6.3.3 Rela√ß√£o entre Cluster e Previsibilidade

| Cluster | MAE M√©dio | Interpreta√ß√£o |
|---------|-----------|---------------|
| **Cluster 1** (88 CPEs) | ‚Äì | Cluster agregado de baixo/moderado consumo |
| **Cluster 0** (1 CPE) | ‚Äì | √önico CPE de consumo extremo |

**Conclus√£o**: O clustering K-Means ficou desbalanceado (1 vs 88), dificultando correlacionar clusters com previsibilidade. A an√°lise de previsibilidade deve ser feita por CPE, n√£o pelos clusters atuais.

### 6.4 Utilidade Pr√°tica para o Munic√≠pio da Maia

#### 6.4.1 Aplica√ß√µes Imediatas

**1. Planeamento Energ√©tico**
- **Uso**: Previs√µes semanais com ARIMA para negocia√ß√£o de contratos
- **Precis√£o**: Erro t√≠pico de 3-10% (MAPE) √© aceit√°vel para planeamento m√©dio prazo
- **Benef√≠cio**: Redu√ß√£o de custos por evitar penaliza√ß√µes de consumo fora de contrato

**2. Dete√ß√£o de Anomalias**
- **Uso**: Alertas quando consumo real > previs√£o + 2œÉ
- **Clusters**: Outliers identificados por DBSCAN s√£o candidatos a auditoria (atual ru√≠do alto: 39.3%)
- **Benef√≠cio**: Identifica√ß√£o precoce de desperd√≠cios ou avarias, com revis√£o de par√¢metros para reduzir ru√≠do

**3. Tarifas Diferenciadas**
- **Uso**: Aplicar tarifas espec√≠ficas por cluster identificado (ap√≥s reequil√≠brio dos clusters)
- **Cluster 0**: Tarifa por demanda (picos altos) ‚Äî atualmente apenas 1 CPE
- **Cluster 1**: Tarifa flat (consumo constante) ‚Äî concentra 88 CPEs
- **Benef√≠cio**: Otimiza√ß√£o de custos por perfil, ap√≥s redistribui√ß√£o ou revis√£o de k

**4. Benchmarking entre Edif√≠cios**
- **Uso**: Comparar CPEs do mesmo cluster (mesma tipologia)
- **Exemplo**: Comparar escolas entre si para identificar inefici√™ncias
- **Benef√≠cio**: Prioriza√ß√£o de investimentos em efici√™ncia energ√©tica

#### 6.4.2 Recomenda√ß√µes Operacionais

**Curto Prazo (0-3 meses)**:
1. Implementar sistema de alertas baseado em ARIMA para os 5 CPEs principais
2. Investigar os 35 outliers identificados por DBSCAN (ru√≠do alto; rever par√¢metros)
3. Criar dashboard com previs√µes semanais

**M√©dio Prazo (3-6 meses)**:
1. Expandir sistema de previs√£o para todos os 89 CPEs
2. Implementar re-treino mensal dos modelos
3. Integrar com sistema de fatura√ß√£o energ√©tica

**Longo Prazo (6-12 meses)**:
1. Desenvolver modelo de previs√£o sazonal (SARIMA com per√≠odo anual)
2. Incorporar vari√°veis ex√≥genas (temperatura, eventos municipais)
3. Avaliar retorno de investimento (ROI) em interven√ß√µes de efici√™ncia

---

## 7. Conclus√µes e Trabalho Futuro

### 7.1 Conclus√µes Principais

#### 7.1.1 Sobre Clustering
‚ö†Ô∏è **Parcial**: K-Means produziu 2 clusters, mas extremamente desbalanceados (1 vs 88 CPEs)  
‚ö†Ô∏è **Limita√ß√£o**: DBSCAN identificou 35 outliers (39.3%), indicando ru√≠do elevado  
‚ö†Ô∏è **Nota**: A utilidade pr√°tica do clustering atual √© limitada; requer reequil√≠brio ou filtragem de CPEs

#### 7.1.2 Sobre Previs√£o de S√©ries Temporais
‚úÖ **Sucesso**: ARIMA superou baseline em 22%, demonstrando viabilidade  
‚ö†Ô∏è **Parcial**: LSTM n√£o atingiu performance esperada (poss√≠vel falta de dados)  
‚úÖ **Sucesso**: Previs√µes suficientemente precisas para planeamento operacional  

#### 7.1.3 Sobre Modelos Supervisionados
‚úÖ **Sucesso**: MLP demonstrou capacidade competitiva com features agregadas  
‚ö†Ô∏è **Limita√ß√£o**: Dataset pequeno (40 amostras) limita treino robusto  
‚ùå **Insucesso**: XGBoost teve performance abaixo do esperado (requer tuning)  

#### 7.1.4 Sobre Normaliza√ß√£o
‚úÖ **Confirmado**: Cr√≠tica para clustering (como esperado teoricamente)  
‚úÖ **Confirmado**: Sem impacto em modelos de √°rvores (RF, XGBoost)  
‚ö†Ô∏è **Surpresa**: MLP teve melhor performance SEM normaliza√ß√£o (contexto espec√≠fico)  

### 7.2 Limita√ß√µes do Estudo

1. **Dados desbalanceados para clustering**
   - 89 CPEs, mas clusters ficaram 1 vs 88 (K-Means) e 39% ru√≠do (DBSCAN)
   - Impacto: Segmenta√ß√£o pouco acion√°vel; precisa reequil√≠brio ou filtragem pr√©via

2. **Aus√™ncia de Vari√°veis Ex√≥genas**
   - N√£o foram considerados: temperatura, eventos, feriados
   - Impacto: Modelos n√£o capturam influ√™ncias externas

3. **Generaliza√ß√£o**
   - Modelos treinados especificamente para D4Maia
   - N√£o validados para outros munic√≠pios ou contextos

4. **Horizonte de Previs√£o**
   - Focado em 1 semana √† frente
   - N√£o avaliado para horizontes mais longos (mensais/anuais)

### 7.3 Trabalho Futuro

#### 7.3.1 Melhorias nos Modelos

**1. LSTM Aprimorado**
- Incorporar m√∫ltiplas features (n√£o apenas PotActiva)
- Testar arquiteturas mais complexas (Bidirectional LSTM, GRU, Transformers)
- Aumentar dataset com dados de anos anteriores

**2. ARIMA com Vari√°veis Ex√≥genas (ARIMAX)**
- Incorporar temperatura, calend√°rio de eventos
- Testar SARIMA com sazonalidade anual
- Avaliar modelos h√≠bridos (ARIMA + ML)

**3. Ensemble Methods**
- Combinar previs√µes de ARIMA + LSTM + MLP
- Testar stacking de modelos
- Pesos adaptativos por CPE

#### 7.3.2 Novas An√°lises

**1. An√°lise de Causalidade**
- Granger Causality entre CPEs
- Identificar rela√ß√µes de depend√™ncia temporal

**2. Dete√ß√£o de Anomalias Avan√ßada**
- Isolation Forest para dete√ß√£o de outliers temporais
- Autoencoders para aprender padr√µes normais

**3. Segmenta√ß√£o Din√¢mica**
- Clustering temporal (perfis podem mudar sazonalmente)
- Transition matrices entre clusters

#### 7.3.3 Implementa√ß√£o Pr√°tica

**1. Sistema em Produ√ß√£o**
- API REST para previs√µes em tempo real
- Dashboard interativo (Plotly Dash / Streamlit)
- Alertas autom√°ticos por email/SMS

**2. Monitoriza√ß√£o Cont√≠nua**
- Drift detection (mudan√ßas nos padr√µes de dados)
- Re-treino autom√°tico mensal
- A/B testing de novos modelos

**3. Integra√ß√£o com Sistemas Municipais**
- Conectar com sistema de fatura√ß√£o energ√©tica
- Exportar para plataformas de Business Intelligence
- Relat√≥rios autom√°ticos mensais

---

## 8. Refer√™ncias

### 8.1 Metodologia e Frameworks

1. **CRISP-DM**  
   Wirth, R., & Hipp, J. (2000). *CRISP-DM: Towards a standard process model for data mining*. Proceedings of the 4th international conference on the practical applications of knowledge discovery and data mining.

2. **Machine Learning Geral**  
   G√©ron, A. (2019). *Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow* (2nd ed.). O'Reilly Media.

### 8.2 Algoritmos Espec√≠ficos

3. **K-Means Clustering**  
   MacQueen, J. (1967). *Some methods for classification and analysis of multivariate observations*. Proceedings of the fifth Berkeley symposium on mathematical statistics and probability.

4. **DBSCAN**  
   Ester, M., Kriegel, H. P., Sander, J., & Xu, X. (1996). *A density-based algorithm for discovering clusters in large spatial databases with noise*. Kdd, 96(34), 226-231.

5. **ARIMA**  
   Box, G. E., Jenkins, G. M., Reinsel, G. C., & Ljung, G. M. (2015). *Time series analysis: forecasting and control* (5th ed.). John Wiley & Sons.

6. **LSTM**  
   Hochreiter, S., & Schmidhuber, J. (1997). *Long short-term memory*. Neural computation, 9(8), 1735-1780.

7. **Random Forest**  
   Breiman, L. (2001). *Random forests*. Machine learning, 45(1), 5-32.

8. **XGBoost**  
   Chen, T., & Guestrin, C. (2016). *Xgboost: A scalable tree boosting system*. Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining.

### 8.3 Bibliotecas Utilizadas

9. **Scikit-learn**  
   Pedregosa, F., et al. (2011). *Scikit-learn: Machine learning in Python*. Journal of machine learning research, 12(Oct), 2825-2830.

10. **TensorFlow/Keras**  
    Abadi, M., et al. (2016). *TensorFlow: A system for large-scale machine learning*. 12th USENIX symposium on operating systems design and implementation.

11. **Statsmodels**  
    Seabold, S., & Perktold, J. (2010). *Statsmodels: Econometric and statistical modeling with python*. Proceedings of the 9th Python in Science Conference.

12. **Pandas & NumPy**  
    McKinney, W. (2011). *pandas: a foundational Python library for data analysis and statistics*. Python for High Performance and Scientific Computing, 14(9).

### 8.4 Recursos Online

- Scikit-learn Documentation: https://scikit-learn.org
- TensorFlow Documentation: https://tensorflow.org
- Statsmodels Documentation: https://www.statsmodels.org

---

## Anexos

### Anexo A: Configura√ß√£o do Ambiente

**Especifica√ß√µes de Hardware**:
- CPU: Intel i7/AMD Ryzen (ou superior)
- RAM: 16GB m√≠nimo
- GPU: Opcional (NVIDIA para LSTM)

**Software**:
- Python: 3.9, 3.10 ou 3.11
- Jupyter Notebook / VS Code
- Bibliotecas principais (ver `requirements.txt`)

### Anexo B: Estrutura de Ficheiros Entregues

```
ProjetoFinal/
‚îú‚îÄ‚îÄ 01_business_data_understanding.ipynb       # Notebook 1
‚îú‚îÄ‚îÄ 02_data_preparation_feature_engineering.ipynb  # Notebook 2
‚îú‚îÄ‚îÄ 03_clustering_kmeans_dbscan.ipynb         # Notebook 3
‚îú‚îÄ‚îÄ 04_timeseries_ARIMA_LSTM.ipynb            # Notebook 4
‚îú‚îÄ‚îÄ 05_supervised_features_RF_XGB_MLP.ipynb   # Notebook 5
‚îú‚îÄ‚îÄ 06_normalization_and_comparisons.ipynb    # Notebook 6
‚îú‚îÄ‚îÄ RELATORIO_FINAL.md                        # Este relat√≥rio
‚îú‚îÄ‚îÄ README.md                                 # Guia do projeto
‚îú‚îÄ‚îÄ data/intermediate/                        # Datasets interm√©dios
‚îÇ   ‚îú‚îÄ‚îÄ d4maia_series_per_cpe.csv
‚îÇ   ‚îú‚îÄ‚îÄ d4maia_cpe_features.csv
‚îÇ   ‚îú‚îÄ‚îÄ d4maia_cpe_clusters.csv
‚îÇ   ‚îú‚îÄ‚îÄ d4maia_ts_results.csv
‚îÇ   ‚îú‚îÄ‚îÄ d4maia_feature_models_results.csv
‚îÇ   ‚îî‚îÄ‚îÄ d4maia_final_summary.csv
‚îî‚îÄ‚îÄ requisitos/                               # Scripts de instala√ß√£o
    ‚îú‚îÄ‚îÄ requirements.txt
    ‚îú‚îÄ‚îÄ install_requirements.py
    ‚îú‚îÄ‚îÄ setup_windows.bat
    ‚îî‚îÄ‚îÄ setup_linux_mac.sh
```

### Anexo C: Reprodutibilidade

**Para reproduzir os resultados**:

1. Instalar depend√™ncias:
   ```bash
   cd requisitos
   pip install -r requirements.txt
   ```

2. Executar notebooks em ordem (01 ‚Üí 06)

3. Seeds fixados:
   - `RANDOM_STATE = 42` em todos os modelos
   - `np.random.seed(42)`
   - `tf.random.set_seed(42)`

### Anexo D: Contacto e Cr√©ditos

**Projeto desenvolvido para**:
- UC: Introdu√ß√£o √† Aprendizagem Autom√°tica
- Mestrado em Engenharia Inform√°tica
- Ano Letivo: 2025/2026

**Dataset**:
- Fornecido pelo Munic√≠pio da Maia
- D4Maia - Dados de consumo energ√©tico

---

**Fim do Relat√≥rio**  
*√öltima atualiza√ß√£o: 7 Dezembro 2025*
