# üîå D4Maia - An√°lise e Previs√£o de Consumo Energ√©tico

## Projeto Final | Introdu√ß√£o √† Aprendizagem Autom√°tica - MEI 2025/2026

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://python.org)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.13+-orange.svg)](https://tensorflow.org)
[![Scikit-learn](https://img.shields.io/badge/Scikit--learn-1.3+-green.svg)](https://scikit-learn.org)
[![XGBoost](https://img.shields.io/badge/XGBoost-2.0+-red.svg)](https://xgboost.readthedocs.io)
[![Metodologia](https://img.shields.io/badge/Metodologia-CRISP--DM-purple.svg)]()

---

## üìã √çndice

1. [Descri√ß√£o do Projeto](#-descri√ß√£o-do-projeto)
2. [Objetivos](#-objetivos)
3. [Metodologia CRISP-DM](#-metodologia-crisp-dm)
4. [Principais Resultados](#-principais-resultados)
5. [Estrutura do Projeto](#-estrutura-do-projeto)
6. [Experi√™ncias Realizadas](#-experi√™ncias-realizadas)
7. [Visualiza√ß√µes e Gr√°ficos](#-visualiza√ß√µes-e-gr√°ficos)
8. [Instala√ß√£o e Execu√ß√£o](#-instala√ß√£o-e-execu√ß√£o)
9. [Requisitos Python](#-requisitos-python)
10. [Datasets Gerados](#-datasets-gerados)
11. [Conclus√µes e Aplica√ß√µes Pr√°ticas](#-conclus√µes-e-aplica√ß√µes-pr√°ticas)
12. [Refer√™ncias](#-refer√™ncias)

---

## üìñ Descri√ß√£o do Projeto

Este projeto aplica a metodologia **CRISP-DM** para analisar e prever o consumo energ√©tico de edif√≠cios municipais do **Munic√≠pio da Maia**, utilizando o dataset D4Maia.

### Caracter√≠sticas do Dataset

| Atributo | Descri√ß√£o |
|----------|-----------|
| **Registos** | ~6 milh√µes de leituras |
| **Intervalo** | 15 minutos (96 registos/dia) |
| **CPEs** | 89 C√≥digos de Ponto de Entrega |
| **Per√≠odo** | 2022-2025 |
| **Vari√°veis** | `id`, `CPE`, `hora`, `DadosDeConsumo`, `PotActiva`, `PotReactIndut`, `PotReactCapac` |

### Vari√°veis Principais

- **`CPE`** - C√≥digo do Ponto de Entrega (identificador √∫nico da instala√ß√£o)
- **`hora`** (tstamp) - Timestamp da leitura com precis√£o de 15 minutos
- **`PotActiva`** - Pot√™ncia ativa registada (kWh) - **vari√°vel alvo principal**
- **`DadosDeConsumo`** - Energia consumida para fatura√ß√£o (kWh)
- **`PotReactIndut`** - Pot√™ncia reativa indutiva (VAR)
- **`PotReactCapac`** - Pot√™ncia reativa capacitiva (VAR)

---

## üéØ Objetivos

### Objetivos de Neg√≥cio

1. **Caracteriza√ß√£o de Consumidores** - Identificar perfis distintos de consumo energ√©tico
2. **Dete√ß√£o de Anomalias** - Identificar instala√ß√µes com comportamentos at√≠picos ou desperd√≠cios
3. **Previs√£o de Consumo** - Prever consumo com anteced√™ncia de 1 semana para planeamento

### Objetivos T√©cnicos

| Objetivo | T√©cnicas Utilizadas | M√©tricas |
|----------|---------------------|----------|
| Clustering | K-Means, DBSCAN | Silhouette, Davies-Bouldin, Calinski-Harabasz |
| Previs√£o S√©ries Temporais | ARIMA, LSTM | MAE, RMSE, MAPE |
| Previs√£o com Features | RF, XGBoost, MLP | MAE, RMSE |
| An√°lise de Normaliza√ß√£o | StandardScaler | Compara√ß√£o de m√©tricas com/sem normaliza√ß√£o |

---

## üî¨ Metodologia CRISP-DM

O projeto segue rigorosamente a metodologia **CRISP-DM** (Cross-Industry Standard Process for Data Mining):

| Fase | Notebook | Descri√ß√£o |
|------|----------|-----------|
| **1. Business Understanding** | `01_business_data_understanding.ipynb` | Contexto do Munic√≠pio da Maia, objetivos de neg√≥cio, stakeholders, m√©tricas de sucesso |
| **2. Data Understanding** | `01_business_data_understanding.ipynb` | EDA completo: distribui√ß√µes, correla√ß√µes, pairplot, padr√µes temporais, an√°lise por CPE |
| **3. Data Preparation** | `02_data_preparation_feature_engineering.ipynb` | Limpeza de dados, tratamento de outliers, feature engineering (38 features) |
| **4. Modeling - Clustering** | `03_clustering_kmeans_dbscan.ipynb` | K-Means (8 clusters), DBSCAN (14.9% ru√≠do), caracteriza√ß√£o de perfis |
| **4. Modeling - Time Series** | `04_timeseries_ARIMA_LSTM.ipynb` | ARIMA, LSTM vs Baseline, split 70/30 temporal |
| **4. Modeling - Supervised** | `05_supervised_features_RF_XGB_MLP.ipynb` | RF, XGBoost, MLP com clusters como features |
| **5. Evaluation** | `06_normalization_and_comparisons.ipynb` | Compara√ß√£o final, an√°lise de normaliza√ß√£o, conclus√µes CRISP-DM |

> **Nota:** A fase de Deployment n√£o foi implementada conforme indicado no enunciado.

---

## üèÜ Principais Resultados

### Clustering (Experi√™ncia 1)

| Algoritmo | Clusters | Silhouette | Observa√ß√µes |
|-----------|----------|------------|-------------|
| **K-Means** | 8 | 0.263 | Distribui√ß√£o equilibrada (1.4%-24.3% por cluster) |
| **DBSCAN** | 3 | 0.317 | 14.9% ru√≠do (outliers identificados) |

**Perfis Identificados:**
- Consumidores diurnos (pico 8h-18h)
- Consumidores 24/7 (consumo constante)
- Outliers com padr√µes at√≠picos

### Previs√£o de S√©ries Temporais (Experi√™ncia 2a)

| Modelo | MAE | RMSE | vs Baseline |
|--------|-----|------|-------------|
| **Baseline** (semana anterior) | 1.225 | 2.003 | - |
| **ARIMA** | **0.804** | **1.176** | **‚úì -34.4%** |
| **LSTM** (normalizado) | 1.047 | 1.404 | **‚úì +14.6%** |

> **Melhor modelo:** ARIMA superou consistentemente a baseline em 34.4%

### Previs√£o com Features (Experi√™ncia 2b)

| Modelo | Normaliza√ß√£o | MAE | RMSE |
|--------|--------------|-----|------|
| Random Forest | N√£o | 1.629 | 2.168 |
| Random Forest | Sim | 1.630 | 2.170 |
| XGBoost | N√£o | 1.859 | 2.421 |
| XGBoost | Sim | 1.859 | 2.421 |
| MLP | N√£o | 1.552 | 2.143 |
| MLP | Sim | 1.625 | 2.203 |

### Impacto da Normaliza√ß√£o (Experi√™ncia 3)

| Algoritmo | Impacto | Recomenda√ß√£o |
|-----------|---------|--------------|
| K-Means/DBSCAN | **CR√çTICO** | Sempre normalizar |
| LSTM | **ESSENCIAL** | Sempre normalizar |
| MLP | Vari√°vel | Testar ambas configura√ß√µes |
| RF/XGBoost | Sem impacto | Normaliza√ß√£o opcional |

---

## üóÇÔ∏è Estrutura do Projeto

```
ProjetoFinal/
‚îÇ
‚îú‚îÄ‚îÄ üìì NOTEBOOKS (executar em ordem num√©rica)
‚îÇ   ‚îú‚îÄ‚îÄ 01_business_data_understanding.ipynb   # Business & Data Understanding
‚îÇ   ‚îú‚îÄ‚îÄ 02_data_preparation_feature_engineering.ipynb   # Data Preparation
‚îÇ   ‚îú‚îÄ‚îÄ 03_clustering_kmeans_dbscan.ipynb      # Clustering (K-Means, DBSCAN)
‚îÇ   ‚îú‚îÄ‚îÄ 04_timeseries_ARIMA_LSTM.ipynb         # S√©ries Temporais (ARIMA, LSTM)
‚îÇ   ‚îú‚îÄ‚îÄ 05_supervised_features_RF_XGB_MLP.ipynb # Modelos Supervisionados
‚îÇ   ‚îî‚îÄ‚îÄ 06_normalization_and_comparisons.ipynb  # Avalia√ß√£o Final
‚îÇ
‚îú‚îÄ‚îÄ üìÅ data/
‚îÇ   ‚îî‚îÄ‚îÄ intermediate/                          # Dados interm√©dios gerados
‚îÇ       ‚îú‚îÄ‚îÄ d4maia_series_per_cpe.csv          # S√©ries temporais por CPE
‚îÇ       ‚îú‚îÄ‚îÄ d4maia_cpe_features.csv            # 38 features agregadas
‚îÇ       ‚îú‚îÄ‚îÄ d4maia_ts_train_test_index.csv     # √çndices de split temporal
‚îÇ       ‚îú‚îÄ‚îÄ d4maia_cpe_clusters.csv            # Labels de clusters
‚îÇ       ‚îú‚îÄ‚îÄ d4maia_ts_results.csv              # Resultados ARIMA/LSTM
‚îÇ       ‚îú‚îÄ‚îÄ d4maia_feature_models_results.csv  # Resultados RF/XGB/MLP
‚îÇ       ‚îî‚îÄ‚îÄ d4maia_final_summary.csv           # Resumo comparativo
‚îÇ
‚îú‚îÄ‚îÄ üìÅ requisitos/                             # Scripts de instala√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt                       # Depend√™ncias Python
‚îÇ   ‚îú‚îÄ‚îÄ install_requirements.py
‚îÇ   ‚îú‚îÄ‚îÄ setup_windows.bat
‚îÇ   ‚îî‚îÄ‚îÄ setup_linux_mac.sh
‚îÇ
‚îú‚îÄ‚îÄ üìÑ consumo15m_11_2025.csv                  # Dataset original D4Maia
‚îú‚îÄ‚îÄ üìÑ RELATORIO_FINAL.md                      # Relat√≥rio t√©cnico completo
‚îú‚îÄ‚îÄ üìÑ IAA_Project_2025_2026_v1.pdf            # Enunciado do projeto
‚îî‚îÄ‚îÄ üìÑ README.md                               # Este ficheiro
```

---

## üî¨ Experi√™ncias Realizadas

### Experi√™ncia 1: Clustering (Aprendizagem N√£o Supervisionada)

**Objetivo:** Caracterizar diferentes perfis de consumidores e detetar outliers.

**Algoritmos:**
- **K-Means** com m√©todo do cotovelo e Silhouette Score
- **DBSCAN** com gr√°fico K-distance para escolha de eps

**Features Utilizadas (38 no total):**
- Estat√≠sticas de consumo: `consumo_mean`, `consumo_std`, `consumo_cv`, `consumo_min`, `consumo_max`
- Padr√µes hor√°rios: `hora_pico`, `hora_vale`, `consumo_medio_por_hora`
- Perfis temporais: `racio_dia_noite`, `racio_weekend`, `tendencia_semanal`
- Features do enunciado: `avg_afternoon_peak_value`, `avg_daily_peak_time`, `avg_time_below_50_consumption`

**Visualiza√ß√µes Geradas:**
- M√©todo do cotovelo (in√©rcia vs k)
- Silhouette Score por n√∫mero de clusters
- K-distance plot para DBSCAN
- PCA 2D com clusters coloridos
- Heatmap de caracter√≠sticas por cluster
- Distribui√ß√£o de CPEs por cluster

### Experi√™ncia 2(a): Previs√£o com S√©ries Temporais

**Objetivo:** Prever consumo para a semana seguinte usando dados hist√≥ricos.

**Divis√£o Temporal:**
- **Treino:** 70% (dados mais antigos)
- **Teste:** 30% (dados mais recentes)
- **Lag obrigat√≥rio:** Features calculadas com dados ‚â•1 semana antes da previs√£o

**Modelos:**
- **Baseline:** Consumo da mesma hora, 1 semana antes
- **ARIMA:** Auto-sele√ß√£o de ordem (p,d,q)
- **LSTM:** Rede recorrente com normaliza√ß√£o por CPE

**M√©tricas:**
- MAE (Mean Absolute Error)
- RMSE (Root Mean Squared Error)
- MAPE (Mean Absolute Percentage Error)
- Compara√ß√£o percentual vs Baseline

### Experi√™ncia 2(b): Previs√£o com Features Agregadas

**Objetivo:** Usar features agregadas para prever consumo m√©dio semanal.

**Modelos:**
- **Random Forest** (n_estimators=100)
- **XGBoost** (n_estimators=100, max_depth=6)
- **MLP** (hidden_layers=[64, 32], epochs=100)

**Features Adicionais:**
- `cluster_kmeans` e `cluster_dbscan` (resultados do clustering como features)

**Testes de Normaliza√ß√£o:**
- Cada modelo testado COM e SEM StandardScaler

### Experi√™ncia 3: An√°lise de Normaliza√ß√£o

**Objetivo:** Quantificar o impacto da normaliza√ß√£o em cada fam√≠lia de algoritmos.

**Conclus√µes Documentadas:**
- Clustering baseado em dist√¢ncia: normaliza√ß√£o obrigat√≥ria
- Redes neuronais (LSTM, MLP): normaliza√ß√£o recomendada
- Modelos baseados em √°rvores (RF, XGBoost): normaliza√ß√£o sem impacto

---

## üìä Visualiza√ß√µes e Gr√°ficos

### Notebook 01 - Data Understanding

| Visualiza√ß√£o | Descri√ß√£o |
|--------------|-----------|
| Histogramas por vari√°vel | Distribui√ß√£o de PotActiva, PotReactIndut, PotReactCapac, DadosDeConsumo |
| Box plots | Identifica√ß√£o visual de outliers |
| Matriz de correla√ß√£o (heatmap) | Correla√ß√µes entre vari√°veis num√©ricas |
| **Pairplot (scatter matrix)** | Rela√ß√µes entre pares de features |
| Consumo por hora do dia | Padr√£o de consumo hor√°rio agregado |
| Consumo por dia da semana | Padr√£o semanal |
| Heatmap hora √ó dia | Consumo m√©dio por hora e dia da semana |
| S√©ries temporais exemplo | Consumo ao longo do tempo para CPEs exemplo |

### Notebook 03 - Clustering

| Visualiza√ß√£o | Descri√ß√£o |
|--------------|-----------|
| Elbow Method | In√©rcia vs n√∫mero de clusters (K-Means) |
| Silhouette Score | Qualidade dos clusters por k |
| K-distance plot | Escolha autom√°tica de eps (DBSCAN) |
| PCA 2D | Proje√ß√£o dos clusters em 2 dimens√µes |
| Heatmap de perfis | Caracter√≠sticas m√©dias por cluster |
| Distribui√ß√£o de clusters | N√∫mero de CPEs por cluster |
| Compara√ß√£o K-Means vs DBSCAN | Tabela de conting√™ncia |

### Notebook 04 - S√©ries Temporais

| Visualiza√ß√£o | Descri√ß√£o |
|--------------|-----------|
| Boxplot MAE por modelo | Distribui√ß√£o do erro por modelo |
| Boxplot RMSE por modelo | Distribui√ß√£o do erro quadr√°tico |
| Barplot MAE por CPE | Compara√ß√£o por CPE e modelo |
| Previs√£o vs Real | S√©rie temporal prevista vs observada |

### Notebook 05 - Modelos Supervisionados

| Visualiza√ß√£o | Descri√ß√£o |
|--------------|-----------|
| Boxplot MAE por modelo | RF, XGBoost, MLP (com/sem normaliza√ß√£o) |
| Barplot melhoria vs baseline | Percentagem de melhoria |
| Compara√ß√£o normaliza√ß√£o | Impacto visual da normaliza√ß√£o |

### Notebook 06 - Compara√ß√£o Final

| Visualiza√ß√£o | Descri√ß√£o |
|--------------|-----------|
| Distribui√ß√£o K-Means e DBSCAN | N√∫mero de CPEs por cluster |
| Boxplot MAE s√©ries temporais | Baseline vs ARIMA vs LSTM |
| Boxplot MAE supervisionados | Todos os modelos |
| Barplot normaliza√ß√£o | Impacto em RF, XGBoost, MLP |
| Compara√ß√£o global | Todos os modelos ordenados por MAE |
| **Erro por cluster** | MAE por cluster K-Means e DBSCAN |
| MAE vs variabilidade | Scatter plot correlacionando erro com CV |

---

## üöÄ Instala√ß√£o e Execu√ß√£o

### Pr√©-requisitos

- **Python:** 3.9, 3.10 ou 3.11
- **pip:** Gestor de pacotes Python
- **RAM:** M√≠nimo 8GB (recomendado 16GB)
- **Espa√ßo em disco:** ~2GB (incluindo dataset e resultados)

### Instala√ß√£o

**Op√ß√£o 1: Windows (PowerShell)**
```powershell
cd ProjetoFinal\requisitos
.\setup_windows.bat
```

**Op√ß√£o 2: Linux/macOS**
```bash
cd ProjetoFinal/requisitos
chmod +x setup_linux_mac.sh
./setup_linux_mac.sh
```

**Op√ß√£o 3: Manual**
```bash
cd ProjetoFinal/requisitos
pip install -r requirements.txt
```

### Execu√ß√£o dos Notebooks

1. **Navegar para a pasta do projeto:**
   ```bash
   cd ProjetoFinal
   ```

2. **Iniciar Jupyter ou VS Code:**
   ```bash
   jupyter notebook
   # ou abrir no VS Code com extens√£o Jupyter
   ```

3. **Executar notebooks em ordem num√©rica (01 ‚Üí 06)**

> ‚ö†Ô∏è **Importante:** Executar os notebooks sequencialmente, pois cada um depende dos ficheiros gerados pelos anteriores.

---

## üì¶ Requisitos Python

### Ficheiro `requirements.txt`

```
# =============================================================================
# D4Maia Project - Requisitos Python
# =============================================================================

# --- Manipula√ß√£o de Dados ---
pandas>=2.0.0
numpy>=1.24.0

# --- Computa√ß√£o Cient√≠fica ---
scipy>=1.11.0

# --- Visualiza√ß√£o ---
matplotlib>=3.7.0
seaborn>=0.12.0

# --- Machine Learning (Scikit-learn) ---
scikit-learn>=1.3.0

# --- S√©ries Temporais (ARIMA) ---
statsmodels>=0.14.0

# --- Deep Learning (LSTM) ---
tensorflow>=2.13.0

# --- Gradient Boosting ---
xgboost>=2.0.0

# --- Utilit√°rios Jupyter ---
jupyter>=1.0.0
ipykernel>=6.25.0
notebook>=7.0.0
```

### Instala√ß√£o Individual (se necess√°rio)

```bash
pip install pandas numpy scipy matplotlib seaborn scikit-learn statsmodels tensorflow xgboost jupyter ipykernel notebook
```

---

## üíæ Datasets Gerados

Durante a execu√ß√£o dos notebooks, s√£o gerados os seguintes ficheiros interm√©dios:

| Ficheiro | Notebook | Descri√ß√£o | Tamanho |
|----------|----------|-----------|---------|
| `d4maia_series_per_cpe.csv` | 02 | S√©ries temporais limpas por CPE | ~400 MB |
| `d4maia_cpe_features.csv` | 02 | 38 features agregadas por CPE | ~5 KB |
| `d4maia_ts_train_test_index.csv` | 04 | √çndices de split temporal | ~2 KB |
| `d4maia_cpe_clusters.csv` | 03 | Labels de clusters (K-Means, DBSCAN) | ~3 KB |
| `d4maia_ts_results.csv` | 04 | M√©tricas de ARIMA/LSTM por CPE | ~4 KB |
| `d4maia_feature_models_results.csv` | 05 | M√©tricas de RF/XGB/MLP | ~5 KB |
| `d4maia_final_summary.csv` | 06 | Tabela resumo comparativa | ~2 KB |

---

## üí° Conclus√µes e Aplica√ß√µes Pr√°ticas

### Resultados T√©cnicos

1. **ARIMA √© o melhor modelo** para previs√£o de s√©ries temporais neste dataset, superando a baseline em 34.4%
2. **Normaliza√ß√£o √© cr√≠tica** para clustering e redes neuronais, mas irrelevante para modelos baseados em √°rvores
3. **8 clusters K-Means** identificam perfis distintos de consumo com distribui√ß√£o equilibrada
4. **DBSCAN identifica 14.9% de outliers**, propor√ß√£o adequada para detec√ß√£o de anomalias
5. **Modelos supervisionados** n√£o superam baseline semanal, mas fornecem baseline t√©cnica s√≥lida

### Aplica√ß√µes para o Munic√≠pio da Maia

| Aplica√ß√£o | Benef√≠cio | Modelo Recomendado |
|-----------|-----------|-------------------|
| Previs√£o semanal para contratos | Redu√ß√£o de custos | ARIMA |
| Caracteriza√ß√£o de edif√≠cios | Tarifas diferenciadas | K-Means |
| Dete√ß√£o de anomalias | Identifica√ß√£o de desperd√≠cios | DBSCAN |
| Benchmarking entre instala√ß√µes | Prioriza√ß√£o de investimentos | Clustering |

### Limita√ß√µes e Trabalho Futuro

- **Vari√°veis ex√≥genas:** Incluir temperatura, feriados, eventos especiais
- **Granularidade:** Testar previs√µes di√°rias vs semanais
- **Modelos h√≠bridos:** Combinar ARIMA com features para melhorar previs√µes
- **Mais dados:** Expandir per√≠odo temporal para capturar sazonalidade anual

---

## üìö Refer√™ncias

- **CRISP-DM:** Wirth, R., & Hipp, J. (2000). CRISP-DM: Towards a standard process model for data mining.
- **ARIMA:** Box, G. E., Jenkins, G. M., Reinsel, G. C., & Ljung, G. M. (2015). Time Series Analysis: Forecasting and Control.
- **LSTM:** Hochreiter, S., & Schmidhuber, J. (1997). Long Short-Term Memory. Neural Computation.
- **Random Forest:** Breiman, L. (2001). Random Forests. Machine Learning.
- **XGBoost:** Chen, T., & Guestrin, C. (2016). XGBoost: A Scalable Tree Boosting System.
- **K-Means:** MacQueen, J. (1967). Some methods for classification and analysis of multivariate observations.
- **DBSCAN:** Ester, M., et al. (1996). A density-based algorithm for discovering clusters.

---

## üë• Informa√ß√£o Acad√©mica

| Campo | Valor |
|-------|-------|
| **Unidade Curricular** | Introdu√ß√£o √† Aprendizagem Autom√°tica |
| **Curso** | Mestrado em Engenharia Inform√°tica (MEI) |
| **Ano Letivo** | 2025/2026 |
| **Dataset** | D4Maia (Munic√≠pio da Maia) |
| **Metodologia** | CRISP-DM |

---

## üìù Checklist de Entrega

- [x] Notebooks executados do in√≠cio ao fim (01 ‚Üí 06)
- [x] Todos os artifacts gerados em `data/intermediate/`
- [x] Compara√ß√£o gr√°fica clara entre t√©cnicas
- [x] Baseline implementado e comparado
- [x] Normaliza√ß√£o testada em todos os modelos
- [x] Clusters caracterizados com perfis interpret√°veis
- [x] M√©tricas de clustering (Silhouette, Davies-Bouldin)
- [x] M√©tricas de previs√£o (MAE, RMSE, MAPE)
- [x] Distribui√ß√µes e correla√ß√µes (Data Understanding)
- [x] Pairplot (rela√ß√µes entre pares de features)
- [x] Documenta√ß√£o em PT-PT
- [x] README.md com requisitos e instru√ß√µes

---

**√öltima atualiza√ß√£o:** Janeiro 2026  
**Status:** ‚úÖ Projeto Completo
